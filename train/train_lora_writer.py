# train/train_lora_writer.py
# –û–±—É—á–µ–Ω–∏–µ LoRA –¥–ª—è "–ø–∏—Å–∞—Ç–µ–ª—è" –Ω–∞ Qwen2.5-7B-Instruct
# –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É, –≥–¥–µ —Ç–µ–ø–µ—Ä—å –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç —Ç–æ–ª—å–∫–æ —á–µ–ª–ª–µ–Ω–¥–∂–∏
# –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏: {"messages": [...], "source_type": "post"|"challenge" –∏–ª–∏ sample_type}

import os
import sys
from typing import Dict, Any
from datetime import datetime

import torch
from datasets import load_dataset
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    BitsAndBytesConfig,
)
from dotenv import load_dotenv
import pathlib

# ================== –ë–ê–ó–û–í–´–ï –ü–£–¢–ò ==================
BASE_DIR = str(pathlib.Path(__file__).resolve().parents[1])
if BASE_DIR not in sys.path:
    sys.path.insert(0, BASE_DIR)

load_dotenv(os.path.join(BASE_DIR, ".env"))

# ======== –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É ========
# 1) WRITER_DATASET_PATH (–≤ .env)
# 2) WRITER_DATA_PATH (—Å—Ç–∞—Ä–æ–µ –∏–º—è, –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
# 3) –¥–µ—Ñ–æ–ª—Ç ‚Äî –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –ø–æ—Å—Ç–æ–≤ + —á–µ–ª–ª–µ–Ω–¥–∂–µ–π
DATA_PATH = (
    os.getenv("WRITER_DATASET_PATH")
    or os.getenv("WRITER_DATA_PATH")
    or os.path.join(BASE_DIR, "data", "/home/alex/–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª/Educasion/EngageX/data/writer_rewrite_train.jsonl")
)

# ======== –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Qwen ========
DEFAULT_LOCAL_QWEN = os.path.join(BASE_DIR, "Models", "qwen2.5-7b-instruct")
BASE_MODEL = os.getenv("QWEN_LOCAL_PATH", DEFAULT_LOCAL_QWEN)

# ======== –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º LoRA ========
OUTPUT_DIR = os.getenv(
    "LORA_WRITER_OUTPUT",
    os.path.join(BASE_DIR, "checkpoints", "lora_writer_qwen2_5_7b"),
)

os.makedirs(os.path.dirname(OUTPUT_DIR), exist_ok=True)

print(f"[{datetime.now().isoformat()}] üîß CONFIG:")
print(f"  DATA_PATH  = {DATA_PATH}")
print(f"  OUTPUT_DIR = {OUTPUT_DIR}")
print(f"  BASE_MODEL = {BASE_MODEL}")
print("=====================================\n")

if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç: {DATA_PATH}")

# ================== –ó–ê–ì–†–£–ó–ê–ï–ú –î–ê–¢–ê–°–ï–¢ ==================
print(f"[{datetime.now().isoformat()}] üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç...")
raw_dataset = load_dataset(
    "json",
    data_files={"train": DATA_PATH},
)

full_train = raw_dataset["train"]
full_len = len(full_train)
print(f"[{datetime.now().isoformat()}] üìä –í—Å–µ–≥–æ train-—Å—ç–º–ø–ª–æ–≤: {full_len}")

# === –§–ò–õ–¨–¢–†: –û–°–¢–ê–í–õ–Ø–ï–ú –¢–û–õ–¨–ö–û –ß–ï–õ–õ–ï–ù–î–ñ–ò ==================
def is_challenge(example: Dict[str, Any]) -> bool:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞:
    - example["source_type"] == "challenge"
    - example["sample_type"]  == "challenge"
    –ï—Å–ª–∏ –ø–æ–ª—è –Ω–µ—Ç –≤–æ–æ–±—â–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–∞—Ç–∞—Å–µ—Ç —É–∂–µ –∑–∞—Ä–∞–Ω–µ–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω),
    —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ —á–µ–ª–ª–µ–Ω–¥–∂ –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É.
    """
    st = example.get("source_type") or example.get("sample_type")
    if st is None:
        return True
    return st == "challenge"

print(f"[{datetime.now().isoformat()}] üîç –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–µ–ª–ª–µ–Ω–¥–∂–∏...")
train_dataset = full_train.filter(is_challenge)

challenge_len = len(train_dataset)
print(
    f"[{datetime.now().isoformat()}] ‚úÖ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {challenge_len} —á–µ–ª–ª–µ–Ω–¥–∂-—Å—ç–º–ø–ª–æ–≤ "
    f"(–∏–∑ {full_len} –≤—Å–µ–≥–æ)\n"
)

if challenge_len == 0:
    raise RuntimeError(
        "–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ 'challenge' –¥–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç. "
        "–ü—Ä–æ–≤–µ—Ä—å –ø–æ–ª—è source_type/sample_type –≤ jsonl."
    )

# ================== –ó–ê–ì–†–£–ó–ö–ê –¢–û–ö–ï–ù–ê–ô–ó–ï–†–ê –ò –ú–û–î–ï–õ–ò ==================
print(f"[{datetime.now().isoformat()}] üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∏ –º–æ–¥–µ–ª—å...")

tokenizer = AutoTokenizer.from_pretrained(
    BASE_MODEL,
    trust_remote_code=True,
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

pad_id = tokenizer.pad_token_id

quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
)

model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL,
    trust_remote_code=True,
    quantization_config=quant_config,
    device_map="auto",
)

model = prepare_model_for_kbit_training(model)

# –ù–µ–º–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
model.config.pad_token_id = pad_id
model.config.use_cache = False  # —á—Ç–æ–±—ã Trainer –Ω–µ —Ä—É–≥–∞–ª—Å—è, –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏

# ================== LoRA ==================
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=[
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj",
    ],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# ================== –¢–û–ö–ï–ù–ò–ó–ê–¶–ò–Ø ==================
MAX_LEN = int(os.getenv("WRITER_MAX_LEN", "1024"))

def tokenize_fn(example: Dict[str, Any]) -> Dict[str, Any]:
    messages = example["messages"]

    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False,
    )

    enc = tokenizer(
        text,
        max_length=MAX_LEN,
        padding="max_length",
        truncation=True,
        return_attention_mask=True,
    )

    enc["labels"] = enc["input_ids"].copy()
    return enc

print(f"[{datetime.now().isoformat()}] ‚úÇÔ∏è –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç —á–µ–ª–ª–µ–Ω–¥–∂–µ–π...")
tokenized_train = train_dataset.map(
    tokenize_fn,
    batched=False,
    remove_columns=train_dataset.column_names,
)

# ================== –¢–†–ï–ù–ò–†–û–í–ö–ê ==================
train_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    num_train_epochs=3,
    learning_rate=2e-4,
    logging_steps=5,
    save_steps=50,
    save_total_limit=3,
    bf16=True,
    optim="paged_adamw_8bit",
    lr_scheduler_type="cosine",
    warmup_ratio=0.03,
    report_to="none",
)

trainer = Trainer(
    model=model,
    args=train_args,
    train_dataset=tokenized_train,
    tokenizer=tokenizer,
)

if __name__ == "__main__":
    print(f"[{datetime.now().isoformat()}] üöÄ –°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è LoRA —Ç–æ–ª—å–∫–æ –Ω–∞ —á–µ–ª–ª–µ–Ω–¥–∂–∞—Ö...")
    trainer.train()
    trainer.save_model(OUTPUT_DIR)
    tokenizer.save_pretrained(OUTPUT_DIR)
    print(f"[{datetime.now().isoformat()}] ‚úÖ –û–±—É—á–µ–Ω–∏–µ LoRA –∑–∞–≤–µ—Ä—à–µ–Ω–æ, —á–µ–∫–ø–æ–∏–Ω—Ç: {OUTPUT_DIR}")
