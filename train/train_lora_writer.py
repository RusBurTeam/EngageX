# train/train_lora_writer.py
# –û–±—É—á–µ–Ω–∏–µ LoRA –¥–ª—è "–ø–∏—Å–∞—Ç–µ–ª—è" –Ω–∞ Qwen2.5-7B-Instruct
# –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É, —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –∏–∑ writer_challenges.
#
# –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏ –≤ JSONL (writer_train.jsonl):
# {
#   "messages": [
#       {"role": "system", "content": WRITER_SYSTEM_MSG},
#       {"role": "user", "content": "–ö–∞–Ω–∞–ª: ...\n–¶–µ–ª—å –Ω–µ–¥–µ–ª–∏: ...\n–°—Ç–∏–ª—å: ...\n..."},
#       {"role": "assistant", "content": "<—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç —á–µ–ª–ª–µ–Ω–¥–∂–∞>"}
#   ]
# }
#
# –°—Ç–∏–ª—å —É–∂–µ –∑–∞—à–∏—Ç –≤ user-–ø—Ä–æ–º–ø—Ç —Å—Ç—Ä–æ–∫–æ–π "–°—Ç–∏–ª—å: ...", –ø–æ—ç—Ç–æ–º—É
# –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–ª–µ style –∑–¥–µ—Å—å –Ω–µ –Ω—É–∂–Ω–æ ‚Äî –º—ã –ø—Ä–æ—Å—Ç–æ —É—á–∏–º –º–æ–¥–µ–ª—å
# –Ω–∞ —ç—Ç–∏—Ö –¥–∏–∞–ª–æ–≥–∞—Ö.

import os
import sys
from typing import Dict, Any
from datetime import datetime

import torch
from datasets import load_dataset
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    BitsAndBytesConfig,
)
from dotenv import load_dotenv
import pathlib

# ================== –ë–ê–ó–û–í–´–ï –ü–£–¢–ò ==================
BASE_DIR = str(pathlib.Path(__file__).resolve().parents[1])
if BASE_DIR not in sys.path:
    sys.path.insert(0, BASE_DIR)

load_dotenv(os.path.join(BASE_DIR, ".env"))

# ======== –†–ï–ñ–ò–ú –û–ë–£–ß–ï–ù–ò–Ø: safe / max_vram ========
TRAIN_MODE = os.getenv("WRITER_TRAIN_MODE", "safe").lower()
if TRAIN_MODE not in ("safe", "max_vram"):
    TRAIN_MODE = "safe"

# ======== –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É ========
# –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
# 1) WRITER_DATASET_PATH
# 2) WRITER_DATA_PATH (—Å—Ç–∞—Ä–æ–µ –∏–º—è)
# 3) –¥–µ—Ñ–æ–ª—Ç: ./data/writer_train.jsonl (—Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —ç–∫—Å–ø–æ—Ä—Ç–æ–º)
DATA_PATH = (
    os.getenv("WRITER_DATASET_PATH")
    or os.getenv("WRITER_DATA_PATH")
    or os.path.join(BASE_DIR, "data", "writer_train.jsonl")
)

# ======== –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Qwen ========
DEFAULT_LOCAL_QWEN = os.path.join(BASE_DIR, "Models", "qwen2.5-7b-instruct")
BASE_MODEL = os.getenv("QWEN_LOCAL_PATH", DEFAULT_LOCAL_QWEN)

# ======== –ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º LoRA ========
OUTPUT_DIR = os.getenv(
    "LORA_WRITER_OUTPUT",
    os.path.join(BASE_DIR, "checkpoints", "lora_writer_qwen2_5_7b"),
)

os.makedirs(os.path.dirname(OUTPUT_DIR), exist_ok=True)

print(f"[{datetime.now().isoformat()}] üîß CONFIG:")
print(f"  DATA_PATH         = {DATA_PATH}")
print(f"  OUTPUT_DIR        = {OUTPUT_DIR}")
print(f"  BASE_MODEL        = {BASE_MODEL}")
print(f"  WRITER_TRAIN_MODE = {TRAIN_MODE}")
print("=====================================\n")

if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç: {DATA_PATH}")

# ================== –ó–ê–ì–†–£–ó–ê–ï–ú –î–ê–¢–ê–°–ï–¢ ==================
print(f"[{datetime.now().isoformat()}] üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç...")
raw_dataset = load_dataset(
    "json",
    data_files={"train": DATA_PATH},
)

train_dataset = raw_dataset["train"]
full_len = len(train_dataset)
print(f"[{datetime.now().isoformat()}] üìä –í—Å–µ–≥–æ train-—Å—ç–º–ø–ª–æ–≤: {full_len}\n")

if full_len == 0:
    raise RuntimeError("–î–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å writer_train.jsonl.")

# ================== –ó–ê–ì–†–£–ó–ö–ê –¢–û–ö–ï–ù–ê–ô–ó–ï–†–ê –ò –ú–û–î–ï–õ–ò ==================
print(f"[{datetime.now().isoformat()}] üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä –∏ –º–æ–¥–µ–ª—å...")

tokenizer = AutoTokenizer.from_pretrained(
    BASE_MODEL,
    trust_remote_code=True,
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

pad_id = tokenizer.pad_token_id

# 4-bit QLoRA –ø–æ–¥ 3090: —Å—á–∏—Ç–∞–µ–º –≤ float16
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL,
    trust_remote_code=True,
    quantization_config=quant_config,
    device_map="auto",
)

model = prepare_model_for_kbit_training(model)

# –ù–µ–º–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
model.config.pad_token_id = pad_id
model.config.use_cache = False  # —á—Ç–æ–±—ã Trainer –Ω–µ —Ä—É–≥–∞–ª—Å—è, –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏

# ================== LoRA ==================
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=[
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj",
    ],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# ================== –¢–û–ö–ï–ù–ò–ó–ê–¶–ò–Ø ==================
MAX_LEN = int(os.getenv("WRITER_MAX_LEN", "1024"))


def tokenize_fn(example: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ë–µ—Ä—ë–º —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ messages (system + user + assistant),
    –ø—Ä–∏–º–µ–Ω—è–µ–º chat_template –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º.
    –°—Ç–∏–ª—å —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤–Ω—É—Ç—Ä–∏ user-—Å–æ–æ–±—â–µ–Ω–∏—è –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ "–°—Ç–∏–ª—å: ...",
    –ø–æ—ç—Ç–æ–º—É –∑–¥–µ—Å—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –Ω–∏—á–µ–≥–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.
    """
    messages = example["messages"]

    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=False,
    )

    enc = tokenizer(
        text,
        max_length=MAX_LEN,
        padding="max_length",
        truncation=True,
        return_attention_mask=True,
    )

    # –î–ª—è SFT: –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
    enc["labels"] = enc["input_ids"].copy()
    return enc


print(f"[{datetime.now().isoformat()}] ‚úÇÔ∏è –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç...")
tokenized_train = train_dataset.map(
    tokenize_fn,
    batched=False,
    remove_columns=train_dataset.column_names,
)

# ================== –ù–ê–°–¢–†–û–ô–ö–ò –ü–û–î –†–ï–ñ–ò–ú ==================

if TRAIN_MODE == "safe":
    per_device_bs = 2
    grad_acc_steps = 8          # —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch ‚âà 16
    num_epochs = 3
    use_gradient_checkpointing = True
else:  # max_vram
    per_device_bs = 6           # –º–æ–∂–Ω–æ –ø–æ–¥–∂–∞—Ç—å –¥–æ 5, –µ—Å–ª–∏ –±—É–¥–µ—Ç OOM
    grad_acc_steps = 4          # —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch ‚âà 24
    num_epochs = 2
    use_gradient_checkpointing = False

# Gradient checkpointing ‚Äî —Ç–æ–ª—å–∫–æ –≤ safe-—Ä–µ–∂–∏–º–µ
if use_gradient_checkpointing:
    try:
        model.gradient_checkpointing_enable()
    except Exception:
        pass
    try:
        model.enable_input_require_grads()
    except Exception:
        pass

print(
    f"[{datetime.now().isoformat()}] üßÆ TRAIN MODE = {TRAIN_MODE}, "
    f"per_device_bs={per_device_bs}, grad_acc={grad_acc_steps}, "
    f"epochs={num_epochs}, grad_ckpt={use_gradient_checkpointing}"
)

# ================== –¢–†–ï–ù–ò–†–û–í–ö–ê ==================
train_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=per_device_bs,
    gradient_accumulation_steps=grad_acc_steps,
    num_train_epochs=num_epochs,
    learning_rate=2e-4,
    logging_steps=10,
    fp16=True,                 # 3090 ‚Üí fp16 –æ–∫
    optim="paged_adamw_8bit",
    lr_scheduler_type="cosine",
    warmup_ratio=0.03,
    report_to="none",
    overwrite_output_dir=True,    # —É—á–∏–º LoRA "—Å –Ω—É–ª—è" –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ
    gradient_checkpointing=use_gradient_checkpointing,
    save_strategy="no",           # ‚ùó –ù–ï —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ checkpoint-XXXX
)

trainer = Trainer(
    model=model,
    args=train_args,
    train_dataset=tokenized_train,
    tokenizer=tokenizer,
)

if __name__ == "__main__":
    print(f"[{datetime.now().isoformat()}] üöÄ –°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è LoRA –Ω–∞ —á–µ–ª–ª–µ–Ω–¥–∂–∞—Ö (writer_challenges)...")
    trainer.train()
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
    trainer.save_model(OUTPUT_DIR)
    tokenizer.save_pretrained(OUTPUT_DIR)
    print(f"[{datetime.now().isoformat()}] ‚úÖ –û–±—É—á–µ–Ω–∏–µ LoRA –∑–∞–≤–µ—Ä—à–µ–Ω–æ, —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç: {OUTPUT_DIR}")
